{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from FairRanking.datasets.adult import Adult\n",
    "from FairRanking.datasets.law import Law\n",
    "from FairRanking.datasets.compas import Compas\n",
    "from FairRanking.datasets.wiki import Wiki\n",
    "from FairRanking.models.BaseDirectRanker import convert_data_to_tensors\n",
    "from FairRanking.models.DirectRankerAdv import DirectRankerAdv\n",
    "from FairRanking.TrainingFunctions.DirectRankerAdvTrain import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rND(prediction, s, step=10, start=10, protected_group_idx=1, non_protected_group_idx=0):\n",
    "    '''\n",
    "    Computes the normalized Discounted Difference in PyTorch. This metric measures the disparity in \n",
    "    ranking outcomes between protected and non-protected groups in a binary classification context.\n",
    "    Lower values indicate less disparity.\n",
    "\n",
    "    Parameters:\n",
    "    - prediction (torch.Tensor): The model predictions or scores.\n",
    "    - s (torch.Tensor or list): The group labels (0 or 1), indicating whether each instance belongs \n",
    "                                to the protected group or not.\n",
    "    - step (int): The step size to evaluate the ranking at different cutoffs.\n",
    "    - start (int): The starting point for evaluating the ranking.\n",
    "    - protected_group_idx (int): The index representing the protected group in `s`.\n",
    "    - non_protected_group_idx (int): The index representing the non-protected group in `s`.\n",
    "\n",
    "    Returns:\n",
    "    - float: The normalized Discounted Difference score.\n",
    "    '''\n",
    "\n",
    "    # Ensure s is a 1D tensor\n",
    "    #s = torch.as_tensor(s).flatten()\n",
    "\n",
    "    # Check for size mismatch\n",
    "    if len(prediction) != len(s):\n",
    "        raise AssertionError(f'len of prediction {len(prediction)} and s {len(s)} are unequal')\n",
    "\n",
    "    # Count occurrences of each group\n",
    "    unique, counts = torch.unique(s, return_counts=True)\n",
    "    count_dict_all = {k.item(): v.item() for k, v in zip(unique, counts)}\n",
    "    #print(f\"before sorting: {torch.unique(s, return_counts=True)}\")\n",
    "    # Ensure both groups are represented\n",
    "    keys = [protected_group_idx, non_protected_group_idx]\n",
    "    for key in keys:\n",
    "        if key not in count_dict_all:\n",
    "            count_dict_all[key] = 0\n",
    "\n",
    "    # Sort predictions and corresponding group labels\n",
    "    sorted_indices = torch.argsort(prediction, descending=True, dim=0)\n",
    "    print(sorted_indices)\n",
    "    sorted_s = s[sorted_indices]\n",
    "    #print(f\"after sorting: {torch.unique(sorted_s, return_counts=True)}\")\n",
    "\n",
    "    # Create 'worst-case' sorted lists for regularization\n",
    "    # first only the non protected group\n",
    "    fake_horrible_s = torch.cat([torch.full((count_dict_all[non_protected_group_idx],), non_protected_group_idx),\n",
    "                                 torch.full((count_dict_all[protected_group_idx],), protected_group_idx)])\n",
    "\n",
    "    # first only the protected group\n",
    "    fake_horrible_s_2 = torch.cat([torch.full((count_dict_all[protected_group_idx],), protected_group_idx),\n",
    "                                   torch.full((count_dict_all[non_protected_group_idx],), non_protected_group_idx)])\n",
    "\n",
    "    rnd, max_rnd, max_rnd_2 = 0.0, 0.0, 0.0\n",
    "\n",
    "    for i in range(start, len(s), step):\n",
    "        # Count occurrences in top i of the sorted list\n",
    "        unique, counts = torch.unique(sorted_s[:i], return_counts=True)\n",
    "        count_dict_top_i = {k.item(): v.item() for k, v in zip(unique, counts)}\n",
    "\n",
    "        unique, counts = torch.unique(fake_horrible_s[:i], return_counts=True)\n",
    "        count_dict_reg = {k.item(): v.item() for k, v in zip(unique, counts)}\n",
    "\n",
    "        unique_2, counts_2 = torch.unique(fake_horrible_s_2[:i], return_counts=True)\n",
    "        count_dict_reg_2 = {k.item(): v.item() for k, v in zip(unique_2, counts_2)}\n",
    "\n",
    "        for key in keys:\n",
    "            if key not in count_dict_reg:\n",
    "                count_dict_reg[key] = 0\n",
    "            if key not in count_dict_top_i:\n",
    "                count_dict_top_i[key] = 0\n",
    "            if key not in count_dict_reg_2:\n",
    "                count_dict_reg_2[key] = 0\n",
    "        #print(count_dict_top_i)\n",
    "        # Update rnd and max_rnd\n",
    "        rnd += abs(\n",
    "            count_dict_top_i[protected_group_idx] / i - count_dict_all[protected_group_idx] / len(s))\n",
    "        max_rnd += abs(\n",
    "            count_dict_reg[protected_group_idx] / i - count_dict_all[protected_group_idx] / len(s))\n",
    "        max_rnd_2 += abs(\n",
    "            count_dict_reg_2[protected_group_idx] / i - count_dict_all[protected_group_idx] / len(s))\n",
    "\n",
    "    max_rnd = max(max_rnd, max_rnd_2)\n",
    "    print(rnd)\n",
    "    print(max_rnd)\n",
    "    return rnd / max_rnd if max_rnd != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = Law('Race','/Users/robert/Desktop/Bachelor/FairRanker/data')\n",
    "data = Adult('/Users/robert/Desktop/Bachelor/FairRanker/data')\n",
    "#data = Compas()\n",
    "#data = Wiki()\n",
    "(X_train, s_train, y_train), (X_val, s_val, y_val), (X_test, s_test, y_test) = data.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorchbook/lib/python3.10/site-packages/FairRanking/models/BaseDirectRanker.py:205: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_9d63z49rj_/croot/pytorch_1681837279022/work/torch/csrc/utils/tensor_new.cpp:233.)\n",
      "  x0 = torch.tensor(x0, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "X_train0, X_train1, s_train0, s_train1, y_train, X_val0, X_val1, s_val0, s_val1, y_val, X_test0, X_test1, s_test0, s_test1, y_test = convert_data_to_tensors(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10128, 55])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21943661406783785"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from FairRanking.helpers import rND_torch\n",
    "y_test_full = torch.cat((y_test, (-1)*y_test), dim=0)\n",
    "s_test_full = torch.cat((s_test0, s_test1), dim=0)\n",
    "base_rnd = rND(y_test_full, torch.argmax(s_test_full, dim=1))\n",
    "base_rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5064],\n",
      "        [10126],\n",
      "        [10125],\n",
      "        ...,\n",
      "        [    2],\n",
      "        [    1],\n",
      "        [ 2532]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.66092254315369\n",
      "355.1319701526687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22994528627779762"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from FairRanking.helpers import rND_torch\n",
    "y_test_full = y_train\n",
    "s_test_full = s_train0\n",
    "base_rnd = rND(y_test_full, torch.argmax(s_test_full, dim=1))\n",
    "base_rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1,  ..., 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(s_test_full, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1.,  ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_full.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0284\t Test Accuracy: 0.9991\t DI: 133.5815\n",
      "Finished Schedule: [1, 1]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model = DirectRankerAdv(num_features=X_train0.shape[1],\n",
    "                    kernel_initializer=nn.init.normal_,\n",
    "                    hidden_layers=[64, 32, 16],\n",
    "                    bias_layers=[128, 64, 32, 16],\n",
    "            )\n",
    "\n",
    "data_train = [[X_train0, X_train1, y_train, s_train0, s_train1],\n",
    "              [X_test0, X_test1, y_test, s_test0, s_test1]]\n",
    "\n",
    "train(model, data_train, n_epochs=100, path='./', schedule=[1,1], threshold=0.4, adv_lr=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
