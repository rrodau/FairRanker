{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from FairRanking.datasets.adult import Adult\n",
    "from FairRanking.datasets.law import Law\n",
    "from FairRanking.datasets.compas import Compas\n",
    "from FairRanking.datasets.wiki import Wiki\n",
    "from FairRanking.models.DebiasClassifier import DebiasClassifier\n",
    "from FairRanking.TrainingFunctions.DebiasClassifierTrain import train\n",
    "from FairRanking.helpers import rND_torch, nDCG_cls_no_model, auc_estimator, group_pairwise_accuracy, nDCG_cls, auc_estimator2, calc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorchbook/lib/python3.10/site-packages/FairRanking/datasets/compas.py:25: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  self.df.loc[:, x_name] = scaler.fit_transform(self.df.loc[:, x_name])\n",
      "/opt/anaconda3/envs/pytorchbook/lib/python3.10/site-packages/FairRanking/datasets/compas.py:25: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  self.df.loc[:, x_name] = scaler.fit_transform(self.df.loc[:, x_name])\n",
      "/opt/anaconda3/envs/pytorchbook/lib/python3.10/site-packages/FairRanking/datasets/compas.py:25: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  self.df.loc[:, x_name] = scaler.fit_transform(self.df.loc[:, x_name])\n",
      "/opt/anaconda3/envs/pytorchbook/lib/python3.10/site-packages/FairRanking/datasets/compas.py:26: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  self.x_col = self.df.loc[:, x_name]\n"
     ]
    }
   ],
   "source": [
    "#data = Law('Gender','/Users/robert/Desktop/Bachelor/FairRanker/data')\n",
    "#data = Adult('/Users/robert/Desktop/Bachelor/FairRanker/data')\n",
    "data = Compas('/Users/robert/Desktop/Bachelor/FairRanker/data')\n",
    "#data = Wiki()\n",
    "#X_train, s_train, y_train, X_val, s_val, y_val, X_test, s_test, y_test = convert_data_to_tensors(data, build_pairs=False)\n",
    "full_data = data.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DebiasClassifier(num_features=data.get_num_features(),\n",
    "                    kernel_initializer=nn.init.normal_,\n",
    "                    hidden_layers=[60],\n",
    "                    bias_layers=[16, 2],\n",
    "                    num_relevance_classes=data.num_relevance_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\\1000\t Loss: 1.8195387125015259\n",
      "100\\1000\t Loss: 1.9078971147537231\n",
      "200\\1000\t Loss: 2.0612707138061523\n",
      "300\\1000\t Loss: 1.9721601009368896\n",
      "400\\1000\t Loss: 1.9547147750854492\n",
      "500\\1000\t Loss: 1.8968379497528076\n",
      "600\\1000\t Loss: 1.9317378997802734\n",
      "700\\1000\t Loss: 1.9591004848480225\n",
      "800\\1000\t Loss: 1.9043887853622437\n",
      "900\\1000\t Loss: 1.905897617340088\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = train(model, full_data, schedule = [1,0], adv_lr = 0.01, main_lr=0.01, n_epochs = 1000, print_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7128827316199213\n",
      "nDCG:  0.6737509232462537\n",
      "ACC 0.26178861788617885\n",
      "rND:  0.3384815502791561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "data_idx = 2\n",
    "model.eval()\n",
    "y = full_data[data_idx][1]\n",
    "#y = full_data[data_idx][1].squeeze() # if Adult\n",
    "#print(y)\n",
    "with torch.no_grad():\n",
    "    pred = model.predict_proba(full_data[data_idx][0])\n",
    "    #print('GPA: ', group_pairwise_accuracy(pred, full_data[data_idx][1], full_data[data_idx][2]))\n",
    "    print('AUC: ', auc_estimator2(pred, y, multiclass=True))\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "    print('nDCG: ', nDCG_cls(pred, y, esti=False, at=500))\n",
    "    print('ACC', accuracy_score(y, pred))\n",
    "    #print('AUC', auc_sklearn(pred, full_data[data_idx][1]))\n",
    "    print('rND: ', rND_torch(pred, torch.argmax(full_data[data_idx][2], dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8276)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.L1Loss(reduction='mean')(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 1., 3.,  ..., 3., 1., 8.])\n",
      "tensor([1, 1, 5,  ..., 4, 0, 7])\n",
      "(tensor([False,  True]), tensor([2800, 1136]))\n",
      "3936\n"
     ]
    }
   ],
   "source": [
    "data_idx = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model.predict_proba(full_data[data_idx][0])\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "    y = full_data[data_idx][1].squeeze()\n",
    "    print(y)\n",
    "    print(pred)\n",
    "    print(torch.unique(pred == y, return_counts=True))\n",
    "    print(len(full_data[data_idx][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1.,  ..., 0., 0., 1.],\n",
      "        [1., 0., 1.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 8.,  ..., 1., 1., 0.],\n",
      "        ...,\n",
      "        [1., 0., 4.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 1.,  ..., 1., 1., 0.],\n",
      "        [0., 1., 4.,  ..., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(full_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_layers.0.weight\n",
      "feature_layers.0.bias\n",
      "feature_layers.1.weight\n",
      "feature_layers.1.bias\n",
      "debias_layers.0.weight\n",
      "debias_layers.0.bias\n",
      "debias_layers.1.weight\n",
      "debias_layers.1.bias\n",
      "debias_layers.2.weight\n",
      "debias_layers.2.bias\n",
      "additional_main_layers.0.weight\n",
      "additional_main_layers.0.bias\n",
      "additional_main_layers.1.weight\n",
      "additional_main_layers.1.bias\n",
      "output_layer.weight\n",
      "output_layer.bias\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    print(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
